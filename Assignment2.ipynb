{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb389aeb-5c27-4f96-bdf7-fa2ae303da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Flask and VoiceResponse classes\n",
    "from flask import Flask, request\n",
    "from twilio.twiml.voice_response import VoiceResponse\n",
    "\n",
    "# Create a Flask application instance\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Define a route for handling incoming calls (POST method)\n",
    "@app.route(\"/incoming_call\", methods=['POST'])\n",
    "def incoming_call():\n",
    "    # Create a TwiML VoiceResponse object\n",
    "    response = VoiceResponse()\n",
    "\n",
    "    # Add a message to the response using Alice's voice\n",
    "    response.say(\"Welcome! Please say something and I'll respond.\", voice='alice')\n",
    "\n",
    "    # Record user speech with a maximum length of 30 seconds\n",
    "    # and redirect to /process_speech route after recording\n",
    "    response.record(max_length=30, action=\"/process_speech\")\n",
    "\n",
    "    # Convert the VoiceResponse object to a string for Twilio to understand\n",
    "    return str(response)\n",
    "\n",
    "# Run the Flask application in debug mode (useful for development)\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d113ef-1f37-42c5-9526-fab82b13715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "def recognize_speech():\n",
    "    speech_key, service_region = \"d2cd6f43243a4ef1b2e47adeba3f121d\", \"centralindia\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)\n",
    "\n",
    "    print(\"Say something...\")\n",
    "    result = speech_recognizer.recognize_once()\n",
    "    return result.text if result.reason == speechsdk.ResultReason.RecognizedSpeech else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "762ac6e2-0d22-4d34-b823-05ebfc7cf474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_speech(text):\n",
    "    speech_key, service_region = \"d2cd6f43243a4ef1b2e47adeba3f121d\", \"centralindia\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "\n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    synthesizer.speak_text_async(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46352543-41d5-49c1-9042-834731f1ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "772e190b-6d61-452c-bde7-90614f227249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import requests\n",
    "import json\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4424039-2df4-47f6-a738-a9c1994b8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Set your API keys\n",
    "OPENAI_API_KEY = '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'\n",
    "MS_SPEECH_KEY = 'd2cd6f43243a4ef1b2e47adeba3f121d'\n",
    "MS_SERVICE_REGION = 'centralindia'  # e.g., \"eastus\"\n",
    "\n",
    "# Define the OpenAI API endpoint\n",
    "OPENAI_API_URL = 'https://api.openai.com/v1/chat/completions'\n",
    "\n",
    "# Conversation history, starting with the system message\n",
    "conversation_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a chatbot named Ria who can answer anything on General Knowledge in less than 40 words.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "### 1. Microsoft Speech Recognition (ASR)\n",
    "def recognize_speech():\n",
    "    \"\"\"Function to recognize user speech and convert it to text.\"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=MS_SPEECH_KEY, region=MS_SERVICE_REGION)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)\n",
    "    \n",
    "    print(\"Say something...\")\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        return result.text\n",
    "    else:\n",
    "        print(\"Speech not recognized.\")\n",
    "        return None\n",
    "\n",
    "### 2. OpenAI GPT-4O API Call\n",
    "def get_openai_response(conversation):\n",
    "    \"\"\"Function to send the conversation history to GPT-4 API and get a response.\"\"\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {OPENAI_API_KEY}'\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"gpt-4-0125-preview\",\n",
    "        \"messages\": conversation,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "\n",
    "    response = requests.post(OPENAI_API_URL, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "\n",
    "### 3. Microsoft Text-to-Speech (TTS) with Indian Accent\n",
    "def synthesize_speech(text):\n",
    "    \"\"\"Function to convert the assistant's response text to speech using an Indian accent.\"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=MS_SPEECH_KEY, region=MS_SERVICE_REGION)\n",
    "    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "    \n",
    "    # Set the voice to an Indian-accented English voice\n",
    "    speech_config.speech_synthesis_voice_name = \"en-IN-AnanyaNeural\"  # Female voice, can change to en-IN-PrabhatNeural for male\n",
    "    \n",
    "    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    synthesizer.speak_text_async(text)\n",
    "\n",
    "### 4. Check for Exit Conditions\n",
    "def check_exit_condition(user_input):\n",
    "    \"\"\"Function to check if the user wants to exit the conversation.\"\"\"\n",
    "    exit_phrases = [\"thank you\", \"no further queries\", \"exit\", \"goodbye\"]\n",
    "    for phrase in exit_phrases:\n",
    "        if phrase.lower() in user_input.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "### 5. Run the voice conversation with exit condition\n",
    "def run_voice_conversation():\n",
    "    \"\"\"Function to loop the voice conversation between the user and the bot with exit condition.\"\"\"\n",
    "    global conversation_history\n",
    "\n",
    "    while True:\n",
    "        # 1. Recognize user speech input\n",
    "        user_input = recognize_speech()\n",
    "        if user_input:\n",
    "            print(f\"You: {user_input}\")\n",
    "\n",
    "            # Check if the user wants to end the conversation\n",
    "            if check_exit_condition(user_input):\n",
    "                synthesize_speech(\"Thank you for the conversation! Goodbye!\")\n",
    "                break  # Exit the conversation loop\n",
    "\n",
    "            # 2. Add user input to conversation history\n",
    "            conversation_history.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_input\n",
    "            })\n",
    "\n",
    "            # 3. Get the response from OpenAI GPT-4O\n",
    "            openai_response = get_openai_response(conversation_history)\n",
    "\n",
    "            if openai_response:\n",
    "                # Extract assistant's message\n",
    "                assistant_message = openai_response['choices'][0]['message']['content']\n",
    "                print(f\"Ria: {assistant_message}\")\n",
    "\n",
    "                # 4. Add assistant's response to conversation history\n",
    "                conversation_history.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": assistant_message\n",
    "                })\n",
    "\n",
    "                # 5. Synthesize the assistant's response to speech using Indian accent\n",
    "                synthesize_speech(assistant_message)\n",
    "            else:\n",
    "                synthesize_speech(\"Sorry, I could not generate a response. Please try again.\")\n",
    "        else:\n",
    "            synthesize_speech(\"Sorry, I did not hear anything. Please try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_voice_conversation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
